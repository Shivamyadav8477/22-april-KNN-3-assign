{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7979e298-148c-40a8-9fa1-193dfde94ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Write a Python code to implement the KNN classifier algorithm on load_iris dataset in\n",
    "sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452eefe-dda1-4ca8-b288-405c0ca034c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sure, here's a Python code example that demonstrates how to implement the K-Nearest Neighbors (KNN) classifier algorithm using the load_iris dataset from sklearn.datasets. We'll use the scikit-learn library for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "336f052e-f9ca-40c1-9e3d-b730373c86d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN Classifier with k=3: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features (sepal length, sepal width, petal length, petal width)\n",
    "y = iris.target  # Target variable (species)\n",
    "\n",
    "# Split the dataset into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "k = 3  # Number of neighbors to consider (you can adjust this)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Fit the classifier on the training data\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of KNN Classifier with k={k}: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef216f0-4ea6-4043-9f82-b923b90e7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "We first import the necessary libraries, including scikit-learn.\n",
    "We load the Iris dataset using load_iris(), where X contains the feature data (sepal length, sepal width, petal length, petal width) and y contains the target variable (species).\n",
    "We split the dataset into a training set and a test set using train_test_split to evaluate the model's performance.\n",
    "We initialize the KNN classifier with the desired number of neighbors (k).\n",
    "The classifier is trained on the training data using fit.\n",
    "We make predictions on the test data using predict.\n",
    "Finally, we calculate the accuracy of the KNN classifier on the test data using accuracy_score and print the result.\n",
    "You can adjust the value of k and other hyperparameters to experiment with different settings and evaluate their impact on the classifier's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289afc2-1f70-4e61-8942-c6c5c5db6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Write a Python code to implement the KNN regressor algorithm on load_boston dataset in\n",
    "sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9c5c88-3fbc-48bb-be56-140c5497867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Certainly! Here's a Python code example that demonstrates how to implement the K-Nearest Neighbors (KNN) regressor algorithm using the load_boston dataset from sklearn.datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5def2d0f-4506-4950-b007-0df4cf77b715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of KNN Regressor with k=5: 30.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = load_boston()\n",
    "X = boston.data  # Features (e.g., crime rate, number of rooms, etc.)\n",
    "y = boston.target  # Target variable (median house price)\n",
    "\n",
    "# Split the dataset into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the KNN regressor\n",
    "k = 5  # Number of neighbors to consider (you can adjust this)\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=k)\n",
    "\n",
    "# Fit the regressor on the training data\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error (MSE) to evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error of KNN Regressor with k={k}: {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ddeb4-3520-4284-9ca5-8a9b445acdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "We import the necessary libraries, including scikit-learn.\n",
    "We load the Boston Housing dataset using load_boston(), where X contains the feature data (e.g., crime rate, number of rooms) and y contains the target variable (median house price).\n",
    "We split the dataset into a training set and a test set using train_test_split to evaluate the model's performance.\n",
    "We initialize the KNN regressor with the desired number of neighbors (k).\n",
    "The regressor is trained on the training data using fit.\n",
    "We make predictions on the test data using predict.\n",
    "Finally, we calculate the mean squared error (MSE) as a measure of the KNN regressor's performance on the test data and print the result.\n",
    "You can adjust the value of k and other hyperparameters to experiment with different settings and evaluate their impact on the regressor's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ac7968-926d-4c55-8917-779ca3b96c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Write a Python code snippet to find the optimal value of K for the KNN classifier algorithm using\n",
    "cross-validation on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59386fd6-c12a-4d43-bc2d-c942138a3794",
   "metadata": {},
   "outputs": [],
   "source": [
    "To find the optimal value of K for the K-Nearest Neighbors (KNN) classifier algorithm using cross-validation on the load_iris dataset from sklearn.datasets, you can perform a grid search over different K values and use cross-validation to evaluate their performance. Here's a Python code snippet to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e93dbeb-0992-4b53-853d-465bb54ebfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K: 1\n",
      "Cross-Validation Accuracy with Best K: 0.95\n",
      "Test Accuracy with Best K: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features (sepal length, sepal width, petal length, petal width)\n",
    "y = iris.target  # Target variable (species)\n",
    "\n",
    "# Split the dataset into a training set and a test set (for final evaluation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define a range of K values to explore\n",
    "k_values = list(range(1, 21))  # You can adjust the range as needed\n",
    "\n",
    "# Initialize variables to store results\n",
    "best_k = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Perform cross-validation to find the optimal K\n",
    "for k in k_values:\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Perform 5-fold cross-validation and compute mean accuracy\n",
    "    scores = cross_val_score(knn_classifier, X_train, y_train, cv=5)\n",
    "    mean_accuracy = np.mean(scores)\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_k = k\n",
    "        best_accuracy = mean_accuracy\n",
    "\n",
    "# Train the KNN classifier with the best K on the full training set\n",
    "best_knn_classifier = KNeighborsClassifier(n_neighbors=best_k)\n",
    "best_knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = best_knn_classifier.score(X_test, y_test)\n",
    "\n",
    "print(f\"Best K: {best_k}\")\n",
    "print(f\"Cross-Validation Accuracy with Best K: {best_accuracy:.2f}\")\n",
    "print(f\"Test Accuracy with Best K: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b063b22-5514-4d99-a7c1-131717247d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "We import the necessary libraries, load the load_iris dataset, and split it into a training set and a test set.\n",
    "We define a range of K values to explore (in this example, from 1 to 20).\n",
    "We perform cross-validation with 5 folds for each K value and compute the mean accuracy across the folds.\n",
    "We keep track of the K value that yields the highest cross-validation accuracy.\n",
    "Finally, we train the KNN classifier with the best K on the full training set and evaluate its performance on the test set.\n",
    "This code will help you find the optimal K value for your KNN classifier using cross-validation on the load_iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204f7d9d-4f96-43ee-901b-e82e26e95cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Implement the KNN regressor algorithm with feature scaling on load_boston dataset in\n",
    "sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d7255-7a04-45e9-a68b-3ab633e4ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "To implement the K-Nearest Neighbors (KNN) regressor algorithm with feature scaling on the load_boston dataset from sklearn.datasets, you can follow these steps. Feature scaling is essential for KNN because it relies on distance metrics, and features with different scales can dominate the distance calculations. Here's a Python code example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961d4488-2b5b-472a-b210-ffd40fbc4965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of KNN Regressor with feature scaling and k=5: 18.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = load_boston()\n",
    "X = boston.data  # Features (e.g., crime rate, number of rooms, etc.)\n",
    "y = boston.target  # Target variable (median house price)\n",
    "\n",
    "# Split the dataset into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler for feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training features and transform both the training and test features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the KNN regressor\n",
    "k = 5  # Number of neighbors to consider (you can adjust this)\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=k)\n",
    "\n",
    "# Fit the regressor on the scaled training data\n",
    "knn_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the scaled test data\n",
    "y_pred = knn_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the mean squared error (MSE) to evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error of KNN Regressor with feature scaling and k={k}: {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3dea7-a0db-474e-9ddb-3c5e09d4dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "We import the necessary libraries, including scikit-learn.\n",
    "We load the Boston Housing dataset and split it into a training set and a test set.\n",
    "We initialize a StandardScaler to perform feature scaling. We fit the scaler on the training features and transform both the training and test features.\n",
    "We initialize the KNN regressor with the desired number of neighbors (k).\n",
    "The regressor is trained on the scaled training data using fit.\n",
    "We make predictions on the scaled test data using predict.\n",
    "Finally, we calculate the mean squared error (MSE) as a measure of the KNN regressor's performance on the test data and print the result.\n",
    "By scaling the features using StandardScaler, we ensure that they have zero mean and unit variance, which helps KNN make more accurate predictions. Adjust the value of k and other hyperparameters as needed for your specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780c928-32a3-498a-b1f5-fab0d25f3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Write a Python code snippet to implement the KNN classifier algorithm with weighted voting on\n",
    "load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292effbc-8658-49e6-866a-70bf529d7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "To implement the K-Nearest Neighbors (KNN) classifier algorithm with weighted voting on the load_iris dataset from sklearn.datasets, you can use the KNeighborsClassifier from scikit-learn and set the weights parameter to 'distance' to enable weighted voting based on the inverse of distances. Here's a Python code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5ead357-83a9-4ac2-91e6-92198f51c2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN Classifier with weighted voting and k=3: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features (sepal length, sepal width, petal length, petal width)\n",
    "y = iris.target  # Target variable (species)\n",
    "\n",
    "# Split the dataset into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the KNN classifier with weighted voting (using 'distance' for weights)\n",
    "k = 3  # Number of neighbors to consider (you can adjust this)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "\n",
    "# Fit the classifier on the training data\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of KNN Classifier with weighted voting and k={k}: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269763c-4b4b-4bbc-839a-db150dd595b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "We import the necessary libraries, including scikit-learn.\n",
    "We load the Iris dataset and split it into a training set and a test set.\n",
    "We initialize the KNeighborsClassifier with the desired number of neighbors (k) and set the weights parameter to 'distance' to enable weighted voting based on the inverse of distances.\n",
    "The classifier is trained on the training data using fit.\n",
    "We make predictions on the test data using predict.\n",
    "Finally, we calculate and print the accuracy of the KNN classifier with weighted voting on the test data.\n",
    "By setting the weights parameter to 'distance', closer neighbors will have a greater influence on the predictions, and farther neighbors will have less influence. You can adjust the value of k and other hyperparameters to experiment with different settings as needed for your specific classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ed81d-57c8-4ce5-9da0-eb775fd69c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Implement a function to standardise the features before applying KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c8237-9102-4e12-aac6-d0c919b0f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "To standardize the features before applying a K-Nearest Neighbors (KNN) classifier, you can create a function that uses the StandardScaler from scikit-learn. Standardization ensures that the features have zero mean and unit variance, which is important for distance-based algorithms like KNN. Here's a Python function to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fddb708-a2ab-41ea-b5bf-39f3412ce5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize_features(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Standardizes the features in the training and test datasets using StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: The training feature data (numpy array or pandas DataFrame).\n",
    "    - X_test: The test feature data (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "    - X_train_scaled: The standardized training features.\n",
    "    - X_test_scaled: The standardized test features.\n",
    "    \"\"\"\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit and transform the scaler on the training features\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Transform the test features using the same scaler\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6c3ef-5ee1-497c-af05-3df4e89f2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "You can use this function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c85e47-f6ca-4a6d-8710-b88676e8bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN Classifier with standardized features and k=3: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features (sepal length, sepal width, petal length, petal width)\n",
    "y = iris.target  # Target variable (species)\n",
    "\n",
    "# Split the dataset into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "X_train_scaled, X_test_scaled = standardize_features(X_train, X_test)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "k = 3  # Number of neighbors to consider (you can adjust this)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Fit the classifier on the standardized training data\n",
    "knn_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the standardized test data\n",
    "y_pred = knn_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of KNN Classifier with standardized features and k={k}: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45003ed9-d659-45f4-9d46-f91fb9e2478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "This function standardizes the training and test features using StandardScaler and returns the standardized datasets, which can then be used for KNN classification.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6776a1-a7b3-4024-9bb5-f7f41f720020",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Write a Python function to calculate the euclidean distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80781f1-8ca6-4211-ab0d-3a318712dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "You can create a Python function to calculate the Euclidean distance between two points in n-dimensional space using the following formula:\n",
    "\n",
    "Euclidean Distance (L2 Norm) between two points P and Q in n-dimensional space:\n",
    "\n",
    "Distance\n",
    "=\n",
    "(\n",
    "�\n",
    "1\n",
    "−\n",
    "�\n",
    "2\n",
    ")\n",
    "2\n",
    "+\n",
    "(\n",
    "�\n",
    "1\n",
    "−\n",
    "�\n",
    "2\n",
    ")\n",
    "2\n",
    "+\n",
    "…\n",
    "+\n",
    "(\n",
    "�\n",
    "1\n",
    "−\n",
    "�\n",
    "2\n",
    ")\n",
    "2\n",
    "Distance= \n",
    "(x \n",
    "1\n",
    "​\n",
    " −x \n",
    "2\n",
    "​\n",
    " ) \n",
    "2\n",
    " +(y \n",
    "1\n",
    "​\n",
    " −y \n",
    "2\n",
    "​\n",
    " ) \n",
    "2\n",
    " +…+(z \n",
    "1\n",
    "​\n",
    " −z \n",
    "2\n",
    "​\n",
    " ) \n",
    "2\n",
    " \n",
    "​\n",
    " \n",
    "\n",
    "Here's a Python function to calculate the Euclidean distance between two points represented as NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da90fb24-a583-4885-8655-b76d5733c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points represented as NumPy arrays.\n",
    "\n",
    "    Parameters:\n",
    "    - point1: NumPy array representing the coordinates of the first point.\n",
    "    - point2: NumPy array representing the coordinates of the second point.\n",
    "\n",
    "    Returns:\n",
    "    - distance: The Euclidean distance between the two points.\n",
    "    \"\"\"\n",
    "    if len(point1) != len(point2):\n",
    "        raise ValueError(\"Points must have the same dimensionality\")\n",
    "    \n",
    "    # Calculate the squared differences for each dimension\n",
    "    squared_diff = np.square(point1 - point2)\n",
    "\n",
    "    # Sum the squared differences and take the square root\n",
    "    distance = np.sqrt(np.sum(squared_diff))\n",
    "\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0d92be-9636-4eb6-99c7-db15eed1e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "You can use this function to calculate the Euclidean distance between two points by passing their coordinates as NumPy arrays. Here's an example of how to use it:\n",
    "\n",
    "python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5795b0-e96e-4df0-b6ce-8af7edee1d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "point1 = np.array([1, 2, 3])\n",
    "point2 = np.array([4, 5, 6])\n",
    "\n",
    "distance = euclidean_distance(point1, point2)\n",
    "print(f\"Euclidean Distance: {distance:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0407f-c8f6-44ef-a8f8-0d84cf4a0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "This code will output the Euclidean distance between point1 and point2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6142ac-89ac-40d2-95dc-9d59b3abc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. Write a Python function to calculate the manhattan distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378162a-c707-4751-85d0-9ce1652a857e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
